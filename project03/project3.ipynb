{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7397e567-af67-4acf-a104-fa203fc92dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make sure these directories are clean before we start\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(\"data/Hurricane-split/train\")\n",
    "    shutil.rmtree(\"data/Hurricane-split/test\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391ba1fc-58dc-46c8-88a4-b75fb67f924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ensure directories exist\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"data/Hurricane-split/train/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data/Hurricane-split/train/no_damage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "Path(\"data/Hurricane-split/test/damage\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data/Hurricane-split/test/no_damage\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef2efb6-b115-460b-b613-663222bd764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_damage_file_paths = os.listdir('data/data_all_modified/damage')\n",
    "all_no_damage_file_paths = os.listdir('data/data_all_modified/no_damage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f16f530e-420a-4b8b-848e-1b1d948cd153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train damage image count:  11336\n",
      "test damage image count:  2834\n",
      "len of overlap:  0\n",
      "train no damage image count:  5721\n",
      "test no damage image count:  1431\n",
      "len of overlap:  0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "train_damage_paths = random.sample(all_damage_file_paths, int(len(all_damage_file_paths)*0.8))\n",
    "print(\"train damage image count: \", len(train_damage_paths))\n",
    "test_damage_paths = [ p for p in all_damage_file_paths if p not in train_damage_paths]\n",
    "print(\"test damage image count: \", len(test_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_damage_paths if p in test_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))\n",
    "\n",
    "train_no_damage_paths = random.sample(all_no_damage_file_paths, int(len(all_no_damage_file_paths)*0.8))\n",
    "print(\"train no damage image count: \", len(train_no_damage_paths))\n",
    "test_no_damage_paths = [ p for p in all_no_damage_file_paths if p not in train_no_damage_paths]\n",
    "print(\"test no damage image count: \", len(test_no_damage_paths))\n",
    "# ensure no overlap:\n",
    "overlap = [p for p in train_no_damage_paths if p in test_no_damage_paths]\n",
    "print(\"len of overlap: \", len(overlap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e8760dd-d95f-4ce7-a6a8-0c3f4362a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for p in train_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data/data_all_modified/damage', p), os.path.join('data/Hurricane-split/train/damage', p) )\n",
    "\n",
    "for p in test_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data/data_all_modified/damage', p), os.path.join('data/Hurricane-split/test/damage', p) )\n",
    "\n",
    "for p in train_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data/data_all_modified/no_damage', p), os.path.join('data/Hurricane-split/train/no_damage', p) )\n",
    "\n",
    "for p in test_no_damage_paths:\n",
    "    shutil.copyfile(os.path.join('data/data_all_modified/no_damage', p), os.path.join('data/Hurricane-split/test/no_damage', p) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5dfef6f-01f0-4bfd-80ee-d61eca8aa5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in train/damage:  11336\n",
      "Files in train/no_damage:  5721\n",
      "Files in test/damage:  2834\n",
      "Files in test/no_damage:  1431\n"
     ]
    }
   ],
   "source": [
    "print(\"Files in train/damage: \", len(os.listdir(\"data/Hurricane-split/train/damage\")))\n",
    "print(\"Files in train/no_damage: \", len(os.listdir(\"data/Hurricane-split/train/no_damage\")))\n",
    "\n",
    "print(\"Files in test/damage: \", len(os.listdir(\"data/Hurricane-split/test/damage\")))\n",
    "print(\"Files in test/no_damage: \", len(os.listdir(\"data/Hurricane-split/test/no_damage\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485c17c1-7d68-4dac-8a33-fbbbe94df983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 20:08:23.864799: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 20:08:23.903375: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 20:08:23.903409: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 20:08:23.904555: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 20:08:23.911155: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 20:08:23.912248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 20:08:25.102723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17057 files belonging to 2 classes.\n",
      "Using 13646 files for training.\n",
      "Using 3411 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "train_data_dir = 'data/Hurricane-split/train/'\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# target image size\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_data_dir,\n",
    "validation_split=0.2,\n",
    "subset=\"both\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size\n",
    ")\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "train_rescale_ds = train_ds.map(lambda image,label:(rescale(image),label))\n",
    "val_rescale_ds = val_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e6857b2-11e3-46dc-a2d2-2fa15da57283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4265 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = 'data/Hurricane-split/test/'\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "test_data_dir,\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    ")\n",
    "\n",
    "# rescale the data\n",
    "rescale = Rescaling(scale=1.0/255)\n",
    "test_rescale_ds = test_ds.map(lambda image,label:(rescale(image),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72bb41f-a2f7-4921-868e-4d93ebec63c4",
   "metadata": {},
   "source": [
    "# ANN with sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a03f702-947b-48a6-9465-e39c965be5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 67500)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 120)               8100120   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 128)               15488     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8115737 (30.96 MB)\n",
      "Trainable params: 8115737 (30.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# create model\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Flatten(input_shape=(img_height,img_width,3)))\n",
    "# input layer\n",
    "model1.add(Dense(120,activation='relu',input_shape=(img_height*img_width,)))\n",
    "\n",
    "# Hidden layer\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "\n",
    "# output layer (2 labels)\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e3f235c-ed44-41cc-82e7-3d3592d7920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 17s 39ms/step - loss: 0.9028 - accuracy: 0.6427 - val_loss: 0.6987 - val_accuracy: 0.6711\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.6072 - accuracy: 0.6959 - val_loss: 0.5600 - val_accuracy: 0.7215\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.6053 - accuracy: 0.6663 - val_loss: 0.5964 - val_accuracy: 0.6681\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.5978 - accuracy: 0.6637 - val_loss: 0.5966 - val_accuracy: 0.6681\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.5979 - accuracy: 0.6611 - val_loss: 0.5684 - val_accuracy: 0.6681\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 16s 38ms/step - loss: 0.5803 - accuracy: 0.6899 - val_loss: 0.6787 - val_accuracy: 0.4186\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 16s 37ms/step - loss: 0.5795 - accuracy: 0.7097 - val_loss: 0.6174 - val_accuracy: 0.6013\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 16s 37ms/step - loss: 0.5740 - accuracy: 0.7074 - val_loss: 0.6078 - val_accuracy: 0.6895\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 16s 36ms/step - loss: 0.5774 - accuracy: 0.7109 - val_loss: 0.5627 - val_accuracy: 0.7282\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 16s 37ms/step - loss: 0.5853 - accuracy: 0.6973 - val_loss: 0.6702 - val_accuracy: 0.4955\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 16s 36ms/step - loss: 0.5724 - accuracy: 0.7221 - val_loss: 0.5577 - val_accuracy: 0.7376\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 16s 37ms/step - loss: 0.5758 - accuracy: 0.7120 - val_loss: 0.6011 - val_accuracy: 0.6743\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 15s 36ms/step - loss: 0.5758 - accuracy: 0.7174 - val_loss: 0.5863 - val_accuracy: 0.6919\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 16s 36ms/step - loss: 0.5800 - accuracy: 0.6940 - val_loss: 0.5580 - val_accuracy: 0.7200\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 15s 36ms/step - loss: 0.5778 - accuracy: 0.7100 - val_loss: 0.5919 - val_accuracy: 0.6995\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 15s 36ms/step - loss: 0.5624 - accuracy: 0.7287 - val_loss: 0.5523 - val_accuracy: 0.7403\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 15s 36ms/step - loss: 0.6632 - accuracy: 0.5904 - val_loss: 0.6457 - val_accuracy: 0.6681\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 15s 35ms/step - loss: 0.6406 - accuracy: 0.6637 - val_loss: 0.6358 - val_accuracy: 0.6681\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 15s 36ms/step - loss: 0.6386 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 15s 35ms/step - loss: 0.6386 - accuracy: 0.6637 - val_loss: 0.6356 - val_accuracy: 0.6681\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.6380 - accuracy: 0.6645\n",
      "[0.6380494236946106, 0.6644783020019531]\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model1.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=val_rescale_ds\n",
    ")\n",
    "\n",
    "results_test = model1.evaluate(test_rescale_ds, batch_size = 128)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5f033-d5a0-46da-beda-9df3ab344d69",
   "metadata": {},
   "source": [
    "# ANN with tanh activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11fa7bb8-ffcc-4222-b487-c7fa24392992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 67500)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 120)               8100120   \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 128)               15488     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8115866 (30.96 MB)\n",
      "Trainable params: 8115866 (30.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# create model\n",
    "model2= Sequential()\n",
    "\n",
    "model2.add(Flatten(input_shape=(img_height,img_width,3)))\n",
    "# input layer\n",
    "model2.add(Dense(120,activation='relu',input_shape=(img_height*img_width,)))\n",
    "\n",
    "# Hidden layer\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "\n",
    "# output layer (2 labels)\n",
    "model2.add(Dense(2, activation='tanh'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "156924d9-4fea-43ff-8c27-f763494614c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "375/427 [=========================>....] - ETA: 1s - loss: 5.1657 - accuracy: 0.6648"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model2\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_rescale_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_rescale_ds\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m results_test \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mevaluate(test_rescale_ds, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_test)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model2.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=15,\n",
    "            validation_data=val_rescale_ds\n",
    ")\n",
    "\n",
    "results_test = model2.evaluate(test_rescale_ds, batch_size = 128)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55761531-2036-40a3-a262-564168dc04e3",
   "metadata": {},
   "source": [
    "# ANN with softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee350b22-6b38-479c-bf7e-9f9565f53d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=(img_height,img_width,3)))\n",
    "# input layer\n",
    "model.add(Dense(120,activation='relu',input_shape=(img_height*img_width,)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# output layer (2 labels)\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "575cf142-d4f1-4fe9-820e-86b4241d357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 67500)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               8100120   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               15488     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8115866 (30.96 MB)\n",
      "Trainable params: 8115866 (30.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d282c0-cc04-466e-b09b-4b4a9150d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "410/427 [===========================>..] - ETA: 0s - loss: 0.9051 - accuracy: 0.6336"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_rescale_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_rescale_ds\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:138\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/core/function/polymorphism/function_type.py:391\u001b[0m, in \u001b[0;36mFunctionType.unpack_inputs\u001b[0;34m(self, bound_parameters)\u001b[0m\n\u001b[1;32m    388\u001b[0m flat \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m sorted_parameters:\n\u001b[1;32m    390\u001b[0m   flat\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 391\u001b[0m       \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbound_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m   )\n\u001b[1;32m    394\u001b[0m dealiased_inputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    395\u001b[0m ids_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/framework/type_spec.py:252\u001b[0m, in \u001b[0;36mTypeSpec.to_tensors\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See TraceType base class for details. Do not override.\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 252\u001b[0m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_component_specs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_components\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensors\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1104\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m-> 1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_pack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_composites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:920\u001b[0m, in \u001b[0;36m_tf_core_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    913\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(flat_structure) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(flat_sequence):\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raise-missing-from\u001b[39;00m\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not pack sequence. Structure had \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m atoms, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflat_sequence had \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m items.  Structure: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, flat_sequence: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(flat_structure), \u001b[38;5;28mlen\u001b[39m(flat_sequence), structure, flat_sequence)\n\u001b[1;32m    919\u001b[0m     )\n\u001b[0;32m--> 920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msequence_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:245\u001b[0m, in \u001b[0;36msequence_like\u001b[0;34m(instance, args)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(instance, _wrapt\u001b[38;5;241m.\u001b[39mObjectProxy):\n\u001b[1;32m    242\u001b[0m   \u001b[38;5;66;03m# For object proxies, first create the underlying type and then re-wrap it\u001b[39;00m\n\u001b[1;32m    243\u001b[0m   \u001b[38;5;66;03m# in the proxy type.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(instance)(sequence_like(instance\u001b[38;5;241m.\u001b[39m__wrapped__, args))\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(instance, CustomNestProtocol):\n\u001b[1;32m    246\u001b[0m   metadata \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39m__tf_flatten__()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    247\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m instance\u001b[38;5;241m.\u001b[39m__tf_unflatten__(metadata, \u001b[38;5;28mtuple\u001b[39m(args))\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/typing.py:1969\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_protocol:\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mhasattr\u001b[39m(instance, attr) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m             \u001b[38;5;66;03m# All *methods* can be blocked by setting them to None.\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m             (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, attr, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m              \u001b[38;5;28mgetattr\u001b[39m(instance, attr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1969\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_get_protocol_attrs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__instancecheck__\u001b[39m(instance)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/typing.py:1881\u001b[0m, in \u001b[0;36m_get_protocol_attrs\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1879\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m annotations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(base, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__annotations__\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[0;32m-> 1881\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(base\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(annotations\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m   1882\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m attr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_abc_\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m attr \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m EXCLUDED_ATTRIBUTES:\n\u001b[1;32m   1883\u001b[0m         attrs\u001b[38;5;241m.\u001b[39madd(attr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=30,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c173e34-f8fd-41e1-ab3a-5d24b7d06c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_rescale_ds, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc1e1a93-a1ef-4461-931f-3a7834350269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7193434834480286"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38a887-154c-4d47-96c7-bdaf83c56935",
   "metadata": {},
   "source": [
    "# Lenet 5 with softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b667e260-1c62-45d2-89d2-3052149e5bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 148, 148, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d_4 (Avera  (None, 74, 74, 6)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 72, 72, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_5 (Avera  (None, 36, 36, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 20736)             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 120)               2488440   \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499822 (9.54 MB)\n",
      "Trainable params: 2499822 (9.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(img_height,img_width,3)))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model_lenet5.add(Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer (2 labels)\n",
    "model_lenet5.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "395b43d0-bd20-4f20-aa13-39e48540e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "427/427 [==============================] - 40s 93ms/step - loss: 0.6030 - accuracy: 0.6932 - val_loss: 0.5118 - val_accuracy: 0.8091\n",
      "Epoch 2/30\n",
      "427/427 [==============================] - 40s 93ms/step - loss: 0.4933 - accuracy: 0.7824 - val_loss: 0.4246 - val_accuracy: 0.8563\n",
      "Epoch 3/30\n",
      "427/427 [==============================] - 37s 88ms/step - loss: 0.4323 - accuracy: 0.8246 - val_loss: 0.4845 - val_accuracy: 0.7954\n",
      "Epoch 4/30\n",
      "427/427 [==============================] - 37s 87ms/step - loss: 0.4066 - accuracy: 0.8391 - val_loss: 0.4301 - val_accuracy: 0.8279\n",
      "Epoch 5/30\n",
      "427/427 [==============================] - 37s 86ms/step - loss: 0.3849 - accuracy: 0.8509 - val_loss: 0.3597 - val_accuracy: 0.8634\n",
      "Epoch 6/30\n",
      "427/427 [==============================] - 36s 84ms/step - loss: 0.3699 - accuracy: 0.8592 - val_loss: 0.3693 - val_accuracy: 0.8531\n",
      "Epoch 7/30\n",
      "427/427 [==============================] - 36s 84ms/step - loss: 0.3452 - accuracy: 0.8688 - val_loss: 0.3371 - val_accuracy: 0.8792\n",
      "Epoch 8/30\n",
      "427/427 [==============================] - 35s 83ms/step - loss: 0.3270 - accuracy: 0.8740 - val_loss: 0.3203 - val_accuracy: 0.8789\n",
      "Epoch 9/30\n",
      "427/427 [==============================] - 35s 81ms/step - loss: 0.3059 - accuracy: 0.8856 - val_loss: 0.3004 - val_accuracy: 0.8930\n",
      "Epoch 10/30\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.2838 - accuracy: 0.8912 - val_loss: 0.2957 - val_accuracy: 0.8971\n",
      "Epoch 11/30\n",
      "427/427 [==============================] - 34s 80ms/step - loss: 0.2677 - accuracy: 0.8962 - val_loss: 0.3136 - val_accuracy: 0.8783\n",
      "Epoch 12/30\n",
      "427/427 [==============================] - 34s 80ms/step - loss: 0.2498 - accuracy: 0.9037 - val_loss: 0.2752 - val_accuracy: 0.8901\n",
      "Epoch 13/30\n",
      "427/427 [==============================] - 35s 83ms/step - loss: 0.2355 - accuracy: 0.9080 - val_loss: 0.2547 - val_accuracy: 0.8962\n",
      "Epoch 14/30\n",
      "427/427 [==============================] - 36s 83ms/step - loss: 0.2200 - accuracy: 0.9139 - val_loss: 0.2476 - val_accuracy: 0.9006\n",
      "Epoch 15/30\n",
      "427/427 [==============================] - 36s 84ms/step - loss: 0.2064 - accuracy: 0.9207 - val_loss: 0.2804 - val_accuracy: 0.8836\n",
      "Epoch 16/30\n",
      "427/427 [==============================] - 34s 81ms/step - loss: 0.1969 - accuracy: 0.9233 - val_loss: 0.2390 - val_accuracy: 0.9091\n",
      "Epoch 17/30\n",
      "427/427 [==============================] - 34s 78ms/step - loss: 0.1845 - accuracy: 0.9273 - val_loss: 0.2367 - val_accuracy: 0.9097\n",
      "Epoch 18/30\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.1739 - accuracy: 0.9313 - val_loss: 0.2296 - val_accuracy: 0.9141\n",
      "Epoch 19/30\n",
      "427/427 [==============================] - 36s 83ms/step - loss: 0.1629 - accuracy: 0.9368 - val_loss: 0.2342 - val_accuracy: 0.9024\n",
      "Epoch 20/30\n",
      "427/427 [==============================] - 36s 85ms/step - loss: 0.1528 - accuracy: 0.9401 - val_loss: 0.2201 - val_accuracy: 0.9135\n",
      "Epoch 21/30\n",
      "427/427 [==============================] - 36s 84ms/step - loss: 0.1430 - accuracy: 0.9447 - val_loss: 0.2166 - val_accuracy: 0.9194\n",
      "Epoch 22/30\n",
      "427/427 [==============================] - 34s 80ms/step - loss: 0.1329 - accuracy: 0.9480 - val_loss: 0.2328 - val_accuracy: 0.9126\n",
      "Epoch 23/30\n",
      "427/427 [==============================] - 35s 83ms/step - loss: 0.1234 - accuracy: 0.9532 - val_loss: 0.2217 - val_accuracy: 0.9164\n",
      "Epoch 24/30\n",
      "427/427 [==============================] - 37s 86ms/step - loss: 0.1130 - accuracy: 0.9563 - val_loss: 0.2255 - val_accuracy: 0.9162\n",
      "Epoch 25/30\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.1042 - accuracy: 0.9601 - val_loss: 0.2196 - val_accuracy: 0.9197\n",
      "Epoch 26/30\n",
      "427/427 [==============================] - 35s 81ms/step - loss: 0.0966 - accuracy: 0.9634 - val_loss: 0.2297 - val_accuracy: 0.9159\n",
      "Epoch 27/30\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.0868 - accuracy: 0.9689 - val_loss: 0.2297 - val_accuracy: 0.9176\n",
      "Epoch 28/30\n",
      "427/427 [==============================] - 37s 86ms/step - loss: 0.0794 - accuracy: 0.9730 - val_loss: 0.2399 - val_accuracy: 0.9120\n",
      "Epoch 29/30\n",
      "427/427 [==============================] - 36s 85ms/step - loss: 0.0711 - accuracy: 0.9748 - val_loss: 0.2436 - val_accuracy: 0.9159\n",
      "Epoch 30/30\n",
      "427/427 [==============================] - 37s 86ms/step - loss: 0.0618 - accuracy: 0.9795 - val_loss: 0.2406 - val_accuracy: 0.9138\n"
     ]
    }
   ],
   "source": [
    "history = model_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=30,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b125693-ca7f-480d-ab5e-7d33149967ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_lenet5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_lenet5\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_rescale_ds, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_lenet5' is not defined"
     ]
    }
   ],
   "source": [
    "results_test = model_lenet5.evaluate(test_rescale_ds, batch_size = 128)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d8ca62a-1443-49a9-b9e1-db7d5e49ecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427/427 [==============================] - 10s 24ms/step - loss: 0.0661 - accuracy: 0.9802\n",
      "[0.06614977866411209, 0.98021399974823]\n"
     ]
    }
   ],
   "source": [
    "results_train = model_lenet5.evaluate(train_rescale_ds, batch_size = 128)\n",
    "print(results_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2945ad-d045-465b-a914-f80605dcf419",
   "metadata": {},
   "source": [
    "# Lenet-5 With Sigmoid Actiation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a43c391b-2bb4-42cb-9ee9-28191a645bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 148, 148, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Avera  (None, 74, 74, 6)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 72, 72, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_3 (Avera  (None, 36, 36, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 20736)             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 120)               2488440   \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499737 (9.54 MB)\n",
      "Trainable params: 2499737 (9.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model2_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model2_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(img_height,img_width,3)))\n",
    "model2_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model2_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model2_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model2_lenet5.add(Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model2_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model2_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer (2 labels)\n",
    "model2_lenet5.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model2_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model2_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "197629c4-a54d-4ea4-b9b3-52087f856ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "427/427 [==============================] - 35s 80ms/step - loss: 0.6186 - accuracy: 0.6831 - val_loss: 0.5423 - val_accuracy: 0.7875\n",
      "Epoch 2/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.4877 - accuracy: 0.7938 - val_loss: 0.5365 - val_accuracy: 0.7147\n",
      "Epoch 3/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.4008 - accuracy: 0.8424 - val_loss: 0.4754 - val_accuracy: 0.7675\n",
      "Epoch 4/20\n",
      "427/427 [==============================] - 35s 83ms/step - loss: 0.3668 - accuracy: 0.8593 - val_loss: 0.3572 - val_accuracy: 0.8736\n",
      "Epoch 5/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.3547 - accuracy: 0.8645 - val_loss: 0.4166 - val_accuracy: 0.8138\n",
      "Epoch 6/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.3423 - accuracy: 0.8692 - val_loss: 0.3444 - val_accuracy: 0.8648\n",
      "Epoch 7/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.3341 - accuracy: 0.8749 - val_loss: 0.3376 - val_accuracy: 0.8745\n",
      "Epoch 8/20\n",
      "427/427 [==============================] - 35s 81ms/step - loss: 0.3239 - accuracy: 0.8762 - val_loss: 0.3741 - val_accuracy: 0.8467\n",
      "Epoch 9/20\n",
      "427/427 [==============================] - 35s 83ms/step - loss: 0.3124 - accuracy: 0.8824 - val_loss: 0.3146 - val_accuracy: 0.8801\n",
      "Epoch 10/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.2984 - accuracy: 0.8869 - val_loss: 0.3437 - val_accuracy: 0.8640\n",
      "Epoch 11/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.2884 - accuracy: 0.8907 - val_loss: 0.2906 - val_accuracy: 0.8886\n",
      "Epoch 12/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.2783 - accuracy: 0.8934 - val_loss: 0.2770 - val_accuracy: 0.8915\n",
      "Epoch 13/20\n",
      "427/427 [==============================] - 35s 81ms/step - loss: 0.2666 - accuracy: 0.8979 - val_loss: 0.2945 - val_accuracy: 0.8836\n",
      "Epoch 14/20\n",
      "427/427 [==============================] - 35s 81ms/step - loss: 0.2568 - accuracy: 0.9035 - val_loss: 0.3311 - val_accuracy: 0.8690\n",
      "Epoch 15/20\n",
      "427/427 [==============================] - 35s 81ms/step - loss: 0.2435 - accuracy: 0.9055 - val_loss: 0.2653 - val_accuracy: 0.8942\n",
      "Epoch 16/20\n",
      "427/427 [==============================] - 35s 81ms/step - loss: 0.2383 - accuracy: 0.9079 - val_loss: 0.2705 - val_accuracy: 0.8945\n",
      "Epoch 17/20\n",
      "427/427 [==============================] - 35s 81ms/step - loss: 0.2290 - accuracy: 0.9122 - val_loss: 0.3059 - val_accuracy: 0.8807\n",
      "Epoch 18/20\n",
      "427/427 [==============================] - 34s 80ms/step - loss: 0.2195 - accuracy: 0.9155 - val_loss: 0.2505 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.2102 - accuracy: 0.9189 - val_loss: 0.2490 - val_accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.2007 - accuracy: 0.9230 - val_loss: 0.2309 - val_accuracy: 0.9053\n"
     ]
    }
   ],
   "source": [
    "history = model2_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=30,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0328da1-e616-4607-b28d-2f2519fa3377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 3s 24ms/step - loss: 0.2312 - accuracy: 0.9109\n",
      "[0.23121997714042664, 0.9109026789665222]\n"
     ]
    }
   ],
   "source": [
    "results_test = model2_lenet5.evaluate(test_rescale_ds, batch_size = 128)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b8b6d-4578-46a6-bee6-4785a2653f75",
   "metadata": {},
   "source": [
    "# Lenet-5 With Tanh Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "044434fd-0a1d-4adc-888a-331ba7e9f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 148, 148, 6)       168       \n",
      "                                                                 \n",
      " average_pooling2d_6 (Avera  (None, 74, 74, 6)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 72, 72, 16)        880       \n",
      "                                                                 \n",
      " average_pooling2d_7 (Avera  (None, 36, 36, 16)        0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 20736)             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 120)               2488440   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2499822 (9.54 MB)\n",
      "Trainable params: 2499822 (9.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model3_lenet5 = models.Sequential()\n",
    "\n",
    "# Layer 1: Convolutional layer with 6 filters of size 3x3, followed by average pooling\n",
    "model3_lenet5.add(layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(img_height,img_width,3)))\n",
    "model3_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2: Convolutional layer with 16 filters of size 3x3, followed by average pooling\n",
    "model3_lenet5.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model3_lenet5.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the feature maps to feed into fully connected layers\n",
    "model3_lenet5.add(Flatten())\n",
    "\n",
    "# Layer 3: Fully connected layer with 120 neurons\n",
    "model3_lenet5.add(layers.Dense(120, activation='relu'))\n",
    "\n",
    "# Layer 4: Fully connected layer with 84 neurons\n",
    "model3_lenet5.add(layers.Dense(84, activation='relu'))\n",
    "\n",
    "# Output layer (2 labels)\n",
    "model3_lenet5.add(layers.Dense(2, activation='tanh'))\n",
    "\n",
    "# Compile model\n",
    "model3_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Generating the summary of the model\n",
    "model3_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7864b-d608-4b42-b304-cbfcc4e1a81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "427/427 [==============================] - 36s 81ms/step - loss: 0.5818 - accuracy: 0.5273 - val_loss: 0.4948 - val_accuracy: 0.5561\n",
      "Epoch 2/30\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.4833 - accuracy: 0.4966 - val_loss: 0.4027 - val_accuracy: 0.3412\n",
      "Epoch 3/30\n",
      "427/427 [==============================] - 35s 83ms/step - loss: 0.4211 - accuracy: 0.4464 - val_loss: 0.5405 - val_accuracy: 0.2870\n",
      "Epoch 4/30\n",
      "427/427 [==============================] - 35s 82ms/step - loss: 0.3604 - accuracy: 0.4391 - val_loss: 0.4182 - val_accuracy: 0.2568\n",
      "Epoch 5/30\n",
      "116/427 [=======>......................] - ETA: 23s - loss: 0.3555 - accuracy: 0.4316"
     ]
    }
   ],
   "source": [
    "history = model3_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=30,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a8319-10f4-431a-ac7e-6222552ef76b",
   "metadata": {},
   "source": [
    "# Alternate Lenet-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9ad7e0f-0e35-4ba7-8f86-44790006ac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 74, 74, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 36, 36, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 17, 17, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 7, 7, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3453634 (13.17 MB)\n",
      "Trainable params: 3453634 (13.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "model_alt_lenet5 = models.Sequential()\n",
    "\n",
    "# 2D convolutional layer with 32 filters of size 3x3\n",
    "model_alt_lenet5.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_height,img_width,3)))\n",
    "# 2D Max pooling layer with 2x2 pooling size\n",
    "model_alt_lenet5.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2D convolutional layer with 32 filters of size 3x3 \n",
    "model_alt_lenet5.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "# 2D Max pooling layer with 2x2 pooling size\n",
    "model_alt_lenet5.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2D convolutional layer with 128 filters of size 3x3\n",
    "model_alt_lenet5.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# 2D Max pooling layer with 2x2 pooling size\n",
    "model_alt_lenet5.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2D convolutional layer with 128 filters of size 3x3\n",
    "model_alt_lenet5.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# 2D Max pooling layer with 2x2 pooling size\n",
    "model_alt_lenet5.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten to feed into fully connected layers\n",
    "model_alt_lenet5.add(layers.Flatten())\n",
    "\n",
    "# 50% dropout\n",
    "model_alt_lenet5.add(layers.Dropout(0.5))\n",
    "\n",
    "# Fully connected layer with 512 neurons\n",
    "model_alt_lenet5.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Fully connected layer with 2 neurons\n",
    "model_alt_lenet5.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model_alt_lenet5.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_alt_lenet5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2033790-f8fd-49f4-ba23-d2b5f46781e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "427/427 [==============================] - 136s 317ms/step - loss: 0.5431 - accuracy: 0.7371 - val_loss: 0.4000 - val_accuracy: 0.8259\n",
      "Epoch 2/25\n",
      "427/427 [==============================] - 138s 322ms/step - loss: 0.3817 - accuracy: 0.8390 - val_loss: 0.3088 - val_accuracy: 0.8789\n",
      "Epoch 3/25\n",
      "427/427 [==============================] - 141s 331ms/step - loss: 0.2906 - accuracy: 0.8837 - val_loss: 0.3106 - val_accuracy: 0.8854\n",
      "Epoch 4/25\n",
      "427/427 [==============================] - 148s 346ms/step - loss: 0.2119 - accuracy: 0.9170 - val_loss: 0.1791 - val_accuracy: 0.9279\n",
      "Epoch 5/25\n",
      "427/427 [==============================] - 142s 332ms/step - loss: 0.1666 - accuracy: 0.9348 - val_loss: 0.3686 - val_accuracy: 0.8440\n",
      "Epoch 6/25\n",
      "427/427 [==============================] - 134s 313ms/step - loss: 0.1465 - accuracy: 0.9421 - val_loss: 0.1943 - val_accuracy: 0.9252\n",
      "Epoch 7/25\n",
      "427/427 [==============================] - 138s 324ms/step - loss: 0.1304 - accuracy: 0.9470 - val_loss: 0.1450 - val_accuracy: 0.9411\n",
      "Epoch 8/25\n",
      "427/427 [==============================] - 142s 332ms/step - loss: 0.1195 - accuracy: 0.9525 - val_loss: 0.1187 - val_accuracy: 0.9534\n",
      "Epoch 9/25\n",
      "427/427 [==============================] - 139s 326ms/step - loss: 0.1119 - accuracy: 0.9543 - val_loss: 0.1141 - val_accuracy: 0.9595\n",
      "Epoch 10/25\n",
      "427/427 [==============================] - 136s 319ms/step - loss: 0.1021 - accuracy: 0.9590 - val_loss: 0.1265 - val_accuracy: 0.9554\n",
      "Epoch 11/25\n",
      "427/427 [==============================] - 132s 309ms/step - loss: 0.1003 - accuracy: 0.9593 - val_loss: 0.1137 - val_accuracy: 0.9569\n",
      "Epoch 12/25\n",
      "427/427 [==============================] - 130s 305ms/step - loss: 0.0917 - accuracy: 0.9637 - val_loss: 0.0872 - val_accuracy: 0.9686\n",
      "Epoch 13/25\n",
      "427/427 [==============================] - 129s 302ms/step - loss: 0.0905 - accuracy: 0.9636 - val_loss: 0.0816 - val_accuracy: 0.9695\n",
      "Epoch 14/25\n",
      "427/427 [==============================] - 128s 300ms/step - loss: 0.0849 - accuracy: 0.9679 - val_loss: 0.1116 - val_accuracy: 0.9601\n",
      "Epoch 15/25\n",
      "427/427 [==============================] - 127s 298ms/step - loss: 0.0812 - accuracy: 0.9688 - val_loss: 0.0755 - val_accuracy: 0.9692\n",
      "Epoch 16/25\n",
      "427/427 [==============================] - 128s 299ms/step - loss: 0.0772 - accuracy: 0.9699 - val_loss: 0.0783 - val_accuracy: 0.9724\n",
      "Epoch 17/25\n",
      "427/427 [==============================] - 133s 311ms/step - loss: 0.0723 - accuracy: 0.9708 - val_loss: 0.0801 - val_accuracy: 0.9683\n",
      "Epoch 18/25\n",
      "427/427 [==============================] - 128s 299ms/step - loss: 0.0723 - accuracy: 0.9715 - val_loss: 0.0764 - val_accuracy: 0.9707\n",
      "Epoch 19/25\n",
      "427/427 [==============================] - 127s 297ms/step - loss: 0.0666 - accuracy: 0.9751 - val_loss: 0.1393 - val_accuracy: 0.9525\n",
      "Epoch 20/25\n",
      "427/427 [==============================] - 131s 307ms/step - loss: 0.0661 - accuracy: 0.9760 - val_loss: 0.0682 - val_accuracy: 0.9730\n",
      "Epoch 21/25\n",
      "427/427 [==============================] - 134s 313ms/step - loss: 0.0613 - accuracy: 0.9774 - val_loss: 0.0750 - val_accuracy: 0.9748\n",
      "Epoch 22/25\n",
      "427/427 [==============================] - 131s 307ms/step - loss: 0.0586 - accuracy: 0.9785 - val_loss: 0.0875 - val_accuracy: 0.9678\n",
      "Epoch 23/25\n",
      "427/427 [==============================] - 129s 303ms/step - loss: 0.0578 - accuracy: 0.9780 - val_loss: 0.0857 - val_accuracy: 0.9719\n",
      "Epoch 24/25\n",
      "427/427 [==============================] - 126s 295ms/step - loss: 0.0533 - accuracy: 0.9804 - val_loss: 0.1108 - val_accuracy: 0.9634\n",
      "Epoch 25/25\n",
      "427/427 [==============================] - 123s 289ms/step - loss: 0.0517 - accuracy: 0.9819 - val_loss: 0.0607 - val_accuracy: 0.9801\n"
     ]
    }
   ],
   "source": [
    "history = model_alt_lenet5.fit(\n",
    "            train_rescale_ds,\n",
    "            batch_size=32,\n",
    "            epochs=25,\n",
    "            validation_data=val_rescale_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4cde22c-11e3-4422-8f9d-3183d50ec282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 9s 65ms/step - loss: 0.0497 - accuracy: 0.9831\n",
      "[0.049680184572935104, 0.9831184148788452]\n"
     ]
    }
   ],
   "source": [
    "results_test = model_alt_lenet5.evaluate(test_rescale_ds, batch_size = 128)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7143f0a-86df-4861-b263-f25b11f02914",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alt_lenet5.save(\"hurricane.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee0215-f183-4a4b-bd89-4a687eec26f6",
   "metadata": {},
   "source": [
    "# Testing the Inference Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ef09b56-02a4-4b58-ab6d-07590c097f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "final_model = tf.keras.models.load_model('models/hurricane.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f1ea335-3593-4475-bf42-b6552fcb5b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 9s 66ms/step - loss: 0.0377 - accuracy: 0.9880\n",
      "[0.037746842950582504, 0.9880421757698059]\n"
     ]
    }
   ],
   "source": [
    "results_test = final_model.evaluate(test_rescale_ds, batch_size=128)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ba5e240-6645-49bf-b12d-fc78da71d918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from chatGPT\n",
    "labels_dataset = test_rescale_ds.map(lambda features, label:label)\n",
    "labels = list(labels_dataset.as_numpy_iterator())\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e110209-021a-4e5f-b364-e9f22e6bc74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from chatGPT\n",
    "my_iterator = iter(test_rescale_ds)\n",
    "first_entry = my_iterator.get_next()[0].numpy()\n",
    "l = first_entry.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dba38f12-8667-4cf7-8e4a-a5b60778baf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [[0.9999983906745911, 1.5237205843732227e-06],\n",
       "  [0.0007256282260641456, 0.9992744326591492],\n",
       "  [3.139949455999158e-08, 0.9999999403953552],\n",
       "  [3.8863421991663927e-07, 0.9999995827674866],\n",
       "  [0.9999603629112244, 3.958683737437241e-05],\n",
       "  [1.7940717498277081e-06, 0.999998152256012],\n",
       "  [0.9999273419380188, 7.257550896611065e-05],\n",
       "  [0.9981266856193542, 0.0018732883036136627],\n",
       "  [0.004130591172724962, 0.9958693385124207],\n",
       "  [0.9999237656593323, 7.618772360729054e-05],\n",
       "  [0.08077516406774521, 0.9192247986793518],\n",
       "  [0.00018121047469321638, 0.9998188018798828],\n",
       "  [0.010800685733556747, 0.9891993403434753],\n",
       "  [0.9999762177467346, 2.367173510720022e-05],\n",
       "  [0.008514531888067722, 0.991485595703125],\n",
       "  [0.9999434351921082, 5.651496030623093e-05],\n",
       "  [0.017641067504882812, 0.982358992099762],\n",
       "  [8.308465027084821e-08, 0.9999998211860657],\n",
       "  [0.9989575743675232, 0.001042312360368669],\n",
       "  [0.9998290538787842, 0.00017098280659411103],\n",
       "  [3.728641604539007e-05, 0.9999626278877258],\n",
       "  [0.9998636245727539, 0.00013652964844368398],\n",
       "  [0.9999162554740906, 8.368759154109284e-05],\n",
       "  [0.9999502301216125, 4.970140435034409e-05],\n",
       "  [0.9855427145957947, 0.014457279816269875],\n",
       "  [0.00023537248489446938, 0.9997646808624268],\n",
       "  [0.9964929223060608, 0.0035070544108748436],\n",
       "  [6.316287226582062e-08, 0.9999998211860657],\n",
       "  [0.9981564283370972, 0.0018434881931170821],\n",
       "  [0.9998083114624023, 0.0001915943721542135],\n",
       "  [0.9997668266296387, 0.00023325817892327905],\n",
       "  [0.9999962449073792, 3.6843466659775004e-06]]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "rsp = requests.post(\"http://172.17.0.1:5000/models/hurricane/v1\", json={\"image\": l})\n",
    "\n",
    "rsp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "979d07f3-aaeb-4296-9e8a-44d32b24dbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 199ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.9999983906745911, 1.5237205843732227e-06],\n",
       " [0.0007256282260641456, 0.9992744326591492],\n",
       " [3.139949455999158e-08, 0.9999999403953552],\n",
       " [3.8863421991663927e-07, 0.9999995827674866],\n",
       " [0.9999603629112244, 3.958683737437241e-05],\n",
       " [1.7940717498277081e-06, 0.999998152256012],\n",
       " [0.9999273419380188, 7.257550896611065e-05],\n",
       " [0.9981266856193542, 0.0018732883036136627],\n",
       " [0.004130591172724962, 0.9958693385124207],\n",
       " [0.9999237656593323, 7.618772360729054e-05],\n",
       " [0.08077516406774521, 0.9192247986793518],\n",
       " [0.00018121047469321638, 0.9998188018798828],\n",
       " [0.010800685733556747, 0.9891993403434753],\n",
       " [0.9999762177467346, 2.367173510720022e-05],\n",
       " [0.008514531888067722, 0.991485595703125],\n",
       " [0.9999434351921082, 5.651496030623093e-05],\n",
       " [0.017641067504882812, 0.982358992099762],\n",
       " [8.308465027084821e-08, 0.9999998211860657],\n",
       " [0.9989575743675232, 0.001042312360368669],\n",
       " [0.9998290538787842, 0.00017098280659411103],\n",
       " [3.728641604539007e-05, 0.9999626278877258],\n",
       " [0.9998636245727539, 0.00013652964844368398],\n",
       " [0.9999162554740906, 8.368759154109284e-05],\n",
       " [0.9999502301216125, 4.970140435034409e-05],\n",
       " [0.9855427145957947, 0.014457279816269875],\n",
       " [0.00023537248489446938, 0.9997646808624268],\n",
       " [0.9964929223060608, 0.0035070544108748436],\n",
       " [6.316287226582062e-08, 0.9999998211860657],\n",
       " [0.9981564283370972, 0.0018434881931170821],\n",
       " [0.9998083114624023, 0.0001915943721542135],\n",
       " [0.9997668266296387, 0.00023325817892327905],\n",
       " [0.9999962449073792, 3.6843466659775004e-06]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.predict(l).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
